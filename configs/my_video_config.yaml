# For example:
multiprocessing: False
path_pretrained_models: './pretrained_models'
dataset:
    data_path: 'data'
    input_type: 'video'                             # Input type. 'video' or 'text'
    queries_csv: 'video_queries.csv'                      # Path to the queries csv file

blip_v2_model_type: blip2-flan-t5-xxl  # Change to blip2-flan-t5-xl for smaller GPUs
blip_half_precision: True
# Add more changes here, following the same format as base_config.yaml
codex:
    temperature: 0.                                 # Temperature for Codex. (Almost) deterministic if 0
    best_of: 1                                      # Number of tries to choose from. Use when temperature > 0
    max_tokens: 512                                 # Maximum number of tokens to generate for Codex
    prompt: ./prompts/chatapi_video.prompt          # Codex prompt file, which defines the API. (doesn't support video for now due to token limits)
    model: gpt-3.5-turbo-16k                        # Codex model to use. [gpt-3.5-turbo, gpt-4]. See openai.Model.list() for available models
execute_code: True                                 # Execute the code after generating it. Only applies to main_batch
